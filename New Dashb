OTIF Performance Dashboard Design

Overview

On-Time In-Full (OTIF) is a key supply chain KPI measuring delivery performance. An On-Time delivery means an order line arrives on or before the promised date ￼ (often with some early delivery tolerance), while an In-Full delivery means the full ordered quantity is received with no shortfall ￼. OTIF combines these – it’s the percentage of orders delivered both on time and in full ￼. In this project, we integrate internal packaging plant shipment data with customer order data from Mars, Nestlé, Unilever, and Mondelez to monitor OTIF. The goal is to match our internal order lines to each customer’s order lines (despite differing table structures) and compute OTIF metrics. Below we outline the proposed data model design, matching & discrepancy logic, ETL transformation steps, calculations, dashboard visuals, and master data needed for a scalable OTIF monitoring solution.

1. Data Model Design

Fact vs. Dimension Tables: We will create a star-schema data model for clarity and performance. The central fact table will be an OTIF Order Lines fact, derived by aligning (merging) internal and customer order line data. Surrounding this fact, we’ll have dimension tables for key entities like Plant, Customer, Material, and Date. This design separates core transaction data from descriptive attributes, enabling flexible slicing and dicing of OTIF metrics.
	•	Fact Table – OTIF Order Lines: This fact table will contain one row per order line shipment (i.e. each internal outgoing order line, matched with the corresponding customer order line). It will consolidate fields from the internal system (e.g. plant code, material code, shipped quantity, shipment date) and from the customer’s data (e.g. PO number, requested delivery date, ordered quantity, customer OTIF indicators). By merging the internal and external data into one fact table, we avoid complex many-to-many relationships and can compute OTIF flags directly per line ￼. Each fact row will include a Purchase Order (PO) number (customer PO reference), Plant code, Material code, internal Delivered Qty, customer Ordered Qty, Requested Delivery Date, Actual Delivery/Ship Date, and any provided customer OTIF metrics or flags. An example structure of the fact table might be:
PO No | Plant | Material | Ordered Qty | Delivered Qty | Requested Date | Delivered Date | Customer_OT_flag | Customer_IF_flag | …
	•	Dimension – Plant: Lists each plant (plant code as key) with plant name and other attributes (location, etc.). This allows showing plant names on visuals instead of codes. The fact table’s PlantCode field links to this dimension (many-to-one, as each fact line has one plant, and each plant appears once in the dimension).
	•	Dimension – Customer: Lists customer identifiers (e.g. a customer ID or name for Mars, Nestlé, etc.). If the internal data uses customer codes, we map those to names here. In our merged fact, we’ll add a Customer column indicating which company’s order the line is (Mars, Nestlé, etc.), and link that to a Customer dimension. This allows filtering the dashboard by customer.
	•	Dimension – Material: Contains product/material codes with descriptions (and perhaps product hierarchy info if needed). The fact’s MaterialCode will join to this (one material to many fact lines). Users can then view reports with material descriptions.
	•	Dimension – Date: A calendar date dimension to support time aggregation (by week, month, etc.). We can have multiple date relationships: e.g. one active link from Date dimension to Requested Delivery Date on the fact (to analyze OTIF by the requested/due date), and possibly an inactive link to Actual Delivered Date if we also want to analyze by actual shipment dates. Using a Date dimension enables weekly/monthly trending and time intelligence (YTD, etc.).

Relationships and Cardinality: All relationships between fact and dimensions will be one-to-many (one on the dimension side, many on the fact side), forming a star schema. For example, Fact OTIF[Plant] → DimPlant[Plant] (many-to-one), Fact OTIF[Customer] → DimCustomer[Customer] (many-to-one), etc. The primary challenge is linking internal records to the correct customer records. Instead of a direct many-to-many join on PO (which Power BI does not handle without a bridge ￼), the merging of data into a single fact table or the use of a bridge table with unique keys will handle the alignment. Our approach is to merge data in Power Query so that each fact row inherently represents the correct pairing of internal and external data (thereby eliminating many-to-many relationships in the model). This merged fact can then be related to dimensions in a straightforward way. If, alternatively, we kept separate Internal and Customer fact tables, we would introduce a bridge (e.g. a DimPO table of unique PO numbers) to link them ￼, but with multiple line items per PO this can get complicated. Merging into one fact table simplifies the model: all required comparisons (internal vs. external) occur in that table, and any one-to-many or many-to-many matching at the data level has been resolved before the data hits the model.

Handling Grain and Aggregation: The fact table grain is the order line shipment level (each internal line, which may correspond to a full or partial delivery of a customer’s order line). This supports line-level drill-down (one can always filter to see individual shipment records). For higher-level analysis (like by PO or by PO+Plant), we don’t need separate aggregated tables – Power BI can aggregate on the fly. For example, to view metrics by PO+Plant, we can simply use the PO and Plant fields (from the fact or their dimensions) together in a visual or create a hierarchy (Customer → PO → Plant → Material) to drill down. The model retains all line details, so a user can start at an aggregated view (e.g. total OTIF% for a given PO at a plant) and drill down to see the underlying line shipments that make up that figure. If performance becomes an issue with extremely large data, we could consider creating a summarized table by PO for quick high-level queries, but initially the live aggregation approach with proper indexing will suffice.

Scalability: This design is scalable for adding new customers or changing business rules. New customer data can be incorporated by extending the unified fact table (e.g. adding their data in the same structure via the ETL process) and adding any new dimension values (e.g. new customer name, new materials) to the respective dimension tables. The schema itself doesn’t need to change – since all customer tables are mapped into the common fact structure, adding a new source is just additional rows with a new Customer label. Likewise, if OTIF logic changes (say the “on-time” window changes or new discrepancy categories are introduced), we can update the calculated columns or measures without altering the overall data model structure. This separation of logic (calculations) from structure (model) means the dashboard can adapt to evolving definitions. In summary, the data model will be a star schema centered on a comprehensive OTIF fact table, ensuring both flexibility in analysis and ease of maintenance.

2. Matching and Discrepancy Logic

To align internal lines with customer lines, we apply a hierarchical matching logic using Purchase Order and other keys. The matching hierarchy is: PO → PO + Plant → PO + Plant + Material Code. In practice, the ETL will attempt matches at the most detailed level needed to get a one-to-one link:
	•	Primary Match on PO: First, try to match records by PO number alone. If a given PO number appears only once on each side (one internal line, one customer line), then it’s a direct one-to-one match. In many cases, however, a PO will have multiple line items. A pure PO join would pair all lines of the same PO, causing a many-to-many situation (each internal line would match to all external lines of that PO). To avoid mismatches, we refine the key.
	•	Secondary Match on PO + Plant: If a PO has multiple lines or partial shipments from different plants, we include the Plant code in the key. For example, if PO 123 was delivered from Plant A and Plant B internally, the customer data may or may not distinguish plant. If the customer data includes our plant code (or some ship-from identifier), we use PO + Plant to narrow matches (so PO 123 from Plant A matches the correct lines in customer data, versus Plant B lines). This handles scenarios where one customer order is fulfilled by multiple plants. If the customer data does not have a plant field, we skip this step – in that case we’d proceed to match by PO + Material.
	•	Tertiary Match on PO + Plant + Material: Finally, to handle multiple line items of the same PO at the same plant, we add Material Code. Typically, within one PO, each material (product) is a separate line. By matching on the combination of PO, Plant, and Material, we ensure that each internal line for a specific product aligns to the corresponding customer order line for that product. This resolves one-to-many matches where a PO has, say, two different materials ordered, or when a partial delivery scenario causes duplicates. In essence, the full composite key (PO+Plant+Material) guarantees a unique match per line in all but the most unusual cases.

Using this hierarchy, we implement a matching algorithm in the ETL (Power Query) that goes through these steps. Practically, we might create a composite key column in each dataset (e.g. Key1 = PO, Key2 = PO&Plant, Key3 = PO&Plant&Material) and use conditional merging: first join on Key3 to match lines where all three fields coincide; for any remaining unmatched, join on Key2 (ignoring material differences, if that scenario arises); and as a last resort, join on Key1. In the final merged table, each internal line will have at most one matching customer line attached. If a customer’s PO line had been delivered in two partial shipments (one PO line to two internal lines), both internal lines will link to the same customer PO+Material record. This is acceptable: it means the customer’s order line was split into two deliveries. We will capture that scenario in the data (the customer’s ordered quantity will repeat on both rows, and we can aggregate to evaluate fulfillment). Conversely, if an internal record doesn’t find any matching PO in the customer data, we flag it as unmatched (e.g. an internal shipment that the customer data didn’t list – possibly an extra or data error). Similarly, a customer line with no internal match would indicate we have an order line that was not delivered (or data missing). These unmatched cases are important discrepancies which the model can highlight (e.g. as “missing delivery” or “missing record” issues), though the primary focus is OTIF metrics on matched lines.

Discrepancy Flags (OTIF logic): Once internal and external data are aligned per line, we determine whether each line was on time and in full. We create calculated boolean flags: is_OT, is_IF, and is_OTIF (1 for true, 0 for false). The logic for these is as follows:
	•	On-Time (is_OT): A line is considered on time if the delivery date meets the customer’s required date criteria. Specifically, we will treat the internal delivery as on-time if it was delivered by the requested date (promised due date), with a tolerance of being up to 2 days early (early deliveries are fine up to 2 days early, but not later than the due date). In formula terms:
is_OT = 1 if Actual_Delivery_Date <= Requested_Delivery_Date AND Actual_Delivery_Date >= Requested_Delivery_Date - 2 days; else 0.
Essentially, delivered on the due date or slightly before is acceptable. (Some customers define an “allowable window” for deliveries ￼ – here we use ±0 days late and up to 2 days early as the window). If the customer’s data provides an explicit “On-Time flag” or a delivery status, we will use that directly (since it may account for their specific grace periods or time-of-day cutoffs). Otherwise, we calculate it from the dates as described.
	•	In-Full (is_IF): A line is in full if the delivered quantity matches the ordered quantity. We set is_IF = 1 if Delivered_Qty >= Ordered_Qty; else 0. In most cases we expect Delivered_Qty to equal Ordered_Qty exactly – if it’s less, the delivery was short (not in full). We assume overshipments (Delivered_Qty slightly more than ordered) are rare or not counted as failures here; the focus is to catch under-deliveries. If the customer data provides an “In-Full” indicator or fill-rate metric, we could use that instead. However, typically a simple equality check suffices. For partial shipments, each internal shipment line would show a delivered qty less than the total ordered qty for that item, so those individual lines would be marked not in-full (since that single shipment didn’t fulfill the order). Only when summed together might they fulfill the order quantity. Our model can evaluate both per-shipment and aggregated fulfillment. In general, if an order line required 100 units and only 90 were delivered (or 100 delivered in multiple parts after the due date), is_IF will be 0.
	•	OTIF (is_OTIF): This is true if and only if both conditions above are met on the order line. We define is_OTIF = 1 if (is_OT = 1 AND is_IF = 1); else 0. In effect, a delivery must be on time and in full to count towards OTIF success ￼. Any failure in either timeliness or quantity will result in OTIF failure (is_OTIF = 0). If customer data directly provides an “OTIF” flag for the line, we will use it (this might encapsulate their own rules for OTIF). Otherwise, we derive it via our flags. For example, if Nestlé’s table has a column indicating OTIF Y/N for each order line, our ETL can bring that in as the is_OTIF value and perhaps still compute our own for cross-checking. In cases where customer-provided and calculated flags differ, that itself is a discrepancy to highlight (e.g. our internal data might say we were on time, but the customer flagged it late – possibly due to a difference in how cut-off times are handled). The model can include such a comparison, but assuming consistent logic, we primarily use one source for the flag to avoid confusion.

Using these flags, we can pinpoint discrepancies on each line:
	•	Late deliveries – lines with is_OT = 0 (missed the time window).
	•	Short deliveries – lines with is_IF = 0 (delivered quantity short of order).
	•	OTIF failures – lines with is_OTIF = 0 (which means either or both of the above issues occurred).

We will compute summary statistics like the percentage of lines that were late, short, or OTIF failures per customer and per plant. For instance, if Mars had 100 order lines and 5 were late, that’s 5% late deliveries. If Plant X handled 50 lines and 10 were short, that’s 20% not in-full for Plant X. These metrics help identify where performance is breaking down. Because our fact table houses both internal and external data, each line record has everything needed to determine these flags. In some cases of partial delivery (one order line split into multiple shipments), none of the individual shipments alone delivered the full quantity by the due date. In such scenarios, each partial shipment will likely fail either is_OT or is_IF (or both), and the overall PO line would be counted as an OTIF failure (we might aggregate the parts to see final outcome, but for line-level analysis each part shows a failure). The data model will allow examining these at whatever granularity is needed – you could group the parts of a split delivery to see that collectively the ordered qty was eventually met, but not on time, for example. The key output of this logic will be columns in the fact table (or measures) indicating OT, IF, OTIF status per line, which feed into the dashboard visuals and metrics described later.

3. Power Query ETL Suggestions

To prepare the data for the model, we will use Power Query (Power BI’s ETL tool) to ingest, transform, and combine the five data sources. Key steps include field mapping, normalization, key handling, and incremental loading as outlined below:
	•	Field Mapping & Standardization: Each of the four customer tables (Mars, Nestlé, Unilever, Mondelez) has its own schema, so we will map their columns to a standard schema before combining. For example, one source might use PurchaseOrder while another uses PO_Number; one might have MaterialCode vs. another SKU. We will rename columns in Power Query to a common set: e.g. PO, Plant, Material, OrderedQty, DeliveredQty, RequestedDate, DeliveredDate, OnTimeFlag, InFullFlag, etc. This ensures consistency. We’ll also align data types (dates as date type, quantities as numbers) and units. If, for instance, one customer provides quantity in cases and another in units, we’ll convert them to a single unit of measure (using known conversion factors) so that comparisons are apples-to-apples. Date fields from customers might be in different formats (text vs date, or separate date/time); we’ll convert all to a standard date (or date/time) format. Additionally, we make sure to trim any extra spaces or standardize the case in fields like PO or Material codes to avoid mis-matches due to formatting differences.
	•	Appending Customer Data: Once column names and types are standardized, we will append the four customer tables into one unified table (let’s call it CustomerOrders). This table will get a new column CustomerName (or ID) to note the source (e.g. “Mars” for all rows coming from the Mars file). The structure of CustomerOrders will be something like: Customer | PO | PO Line (if applicable) | Plant | Material | OrderedQty | RequestedDate | DeliveredDate | DeliveredQty | OTIF_flag | OT_flag | IF_flag | …. Not all customers will have all these fields; for those lacking a field, the column will have nulls or defaults. For example, if Unilever’s data doesn’t include an explicit OTIF flag (they only give dates), the OTIF_flag column for Unilever rows will be blank (and we’ll compute it later). The appending operation stacks the data vertically, giving us one large table of all customer order lines. This setup is future-proof: if a new customer is added, we just include their data in this append (after similar mapping), and a new Customer value (e.g. “NewCust”) will appear – the model will handle it once the Customer dimension is updated with that name.
	•	Merging Internal and External Data: The internal data (let’s call it InternalShipments) contains our packaging plant order lines with fields like PO, Plant, Material, ShippedQty, ShippedDate, etc. We will merge InternalShipments with the combined CustomerOrders to align records. We perform a left outer join from Internal to Customer data using the matching logic described in section 2. In Power Query, this might require multiple merge steps or a custom merge key. One practical approach is to add a new column in both tables as a composite key: e.g. Key = PO & "_" & Plant & "_" & Material. If we assume all customer tables include plant and material (or we fill in a placeholder if not), we can use this composite key for a high-granularity match (PO+Plant+Material). We’d do a merge on this Key to bring in customer fields onto the internal table. For any internal rows that don’t find a match on the full key, we could implement the fallback: try merging on just PO+Material (ignoring plant) or just PO, depending on what data is available. This could be achieved by conditional logic or sequential merges: for example, perform the full key merge; for remaining unmatched internal lines, attempt a second merge query on PO+Material; etc. The result will be a merged table where each row primarily follows an internal shipment record, with additional columns appended from the customer data (like the customer’s ordered quantity, requested date, and any flags).
	•	We must handle one-to-many carefully: If the merge finds multiple customer rows for one internal row (say the same PO+Plant+Material appears twice in customer data), Power Query will initially nest them in a table cell. We should investigate why – it could be duplicate data or an actual scenario of two identical lines. Typically, we expect one match. We can expand the merged results to multiple rows if needed (so the internal line would duplicate for each matching customer line). Similarly, if one customer line matches multiple internal lines (the partial delivery case), each internal line will get the same customer info when expanded. This is desired so that each shipment line is paired with its order context. We might add a flag in the data to denote cases of split deliveries.
	•	For a robust solution, we will include all internal lines in the final output (even if no customer match) and potentially all customer lines (even if no internal match). One way is to do a full outer join between InternalShipments and CustomerOrders. In Power Query, this can be achieved by doing two merges (Internal→Customer and Customer→Internal for the complement) or by merging and then appending leftovers. However, since the question scope is aligning for OTIF, our main interest is delivered lines; pure customer lines with no internal record likely indicate not delivered at all (which could be flagged). We can incorporate those as well: e.g. create a dummy internal entry with zero delivery for such cases. But that might complicate the fact table with pseudo-entries. Alternatively, we keep a separate list of “unfulfilled orders” from customer data to highlight separately. For now, we focus on delivered lines.
	•	Implementing Key Fallbacks: If some customer data lacks plant or uses a different material code, we need to adjust. For example, if a customer table doesn’t have plant, our composite key would fail for multi-plant POs. In such a case, we might modify the key for that customer’s rows to exclude plant (or use a generic placeholder). Our matching logic in the ETL can then say: if a match isn’t found with full key, try matching by PO and Material (for that specific customer). We can perform additional merges or use a custom function to simulate the hierarchy: check if the merged customer fields are null (no match); if so, attempt an alternate lookup (maybe using List functions or by merging a differently keyed query). This is complex but ensures no potential match is missed. After merging, we will likely have columns such as CustomerOrderedQty, CustomerRequestedDate, etc., alongside the internal fields. We will then create the OT, IF flags either here in Power Query (as new columns using the date and quantity comparisons) or later in DAX. If the customer provided flags, we might bring them in as well (e.g. a customer’s own OTIF evaluation).
	•	Data Cleansing – Missing/Duplicate POs: During the merge, we should address any anomalies:
	•	Missing POs: If an internal line’s PO doesn’t exist in any customer table, that line will have nulls for customer fields post-merge. We can tag such rows with an “UnmatchedInternal = TRUE” flag, indicating a discrepancy (we have a shipment that we can’t tie to a customer order – perhaps an order number typo or an urgent shipment not in the original order set). Similarly, any customer orders not matched to internal shipments (if we include them) would be “UnmatchedCustomer = TRUE” (indicating an order line that was not delivered or not recorded in internal data). These flags help isolate data issues beyond OTIF (like data integrity problems).
	•	Duplicate POs: If the same PO number is reused by different customers or different orders, it could cause false matches. We mitigate this by including Customer in the key (e.g. prefixing PO with customer code in the composite key). Since we know which customer’s dataset each line comes from, we can concatenate Customer+PO to ensure uniqueness across companies. This way, a PO “100001” from Nestlé won’t mistakenly merge with PO “100001” from Mars. Within a single customer, duplicate PO numbers shouldn’t happen unless they sent the data twice – we can remove exact duplicate lines from the customer data if found, or aggregate them if needed (but typically each line is unique by a combination of PO and line number or material).
	•	Data Type Alignment: We will ensure the PO fields are all text (so that numeric POs from one source don’t fail to match text POs from another), and that leading zeros or special characters are handled consistently. Material codes likewise should be aligned (if one source calls a material “ABC123” and internal calls it “ABC-123”, a mapping table might be needed – presumably the data provided has a consistent code scheme, but we verify this).
	•	Prepare for Refresh: The Power Query steps will be set up so that on each refresh, the latest data from internal and customer sources is fetched, transformations applied, and the model updated. We will maintain queries for each source (with their specific cleaning), then the unified append query, then the merge to produce the final fact table. Any new records or changes in source will flow through. We’ll also load dimension tables (Plant, Customer, Material) either from reference data or by deducing from fact. For instance, we can generate the Customer dimension by taking the distinct customer names in the appended customer table (plus any that appear in internal data if internal data has a customer field). Plant and Material dimensions might come from internal master data tables if available (for complete info), or we can use the distinct codes present in fact and then lookup descriptions via a reference file. Ensuring these dimension queries are refreshed alongside keeps master data in sync.

In summary, the Power Query ETL will standardize and merge the five data sources into a single coherent dataset ready for analysis. It handles the complex join logic by creating composite keys and performing sequential merges to match order lines as accurately as possible. It also addresses data quality issues (missing or duplicate keys) and makes sure the data is clean (consistent formats, unified units). The output of the ETL process is the OTIF fact table and the dimension tables that feed into the Power BI data model.

4. Calculated Columns and DAX Measures

With the data model in place, we will add calculated columns and DAX measures to implement the OTIF logic and produce the required metrics.

Calculated Columns for OTIF Flags: In the fact table (OTIF Order Lines), we create three Boolean (0/1) calculated columns to classify each line:
	•	is_OT – On Time flag. Formula (DAX) for this could be:

is_OT = 
  IF(
    NOT(ISBLANK([Customer_OT_flag])),
      -- if customer provided an OT flag (e.g. Y/N), use it (assuming 1 for on-time, 0 for late)
      [Customer_OT_flag],
      -- otherwise calculate based on dates:
      IF( [Actual_Delivery_Date] <= [Requested_Date] 
          && [Actual_Delivery_Date] >= DATEADD([Requested_Date], -2, DAY), 
          1, 
          0 
      )
  )

This DAX checks if a customer OT flag was provided. If yes, it uses that (after appropriate conversion if needed). If not, it compares the internal actual delivery date to the requested date (from customer data). We allow the delivery date to be the same or before the requested date; additionally, we allow up to 2 days early (using DATEADD(Requested_Date, -2, DAY) as the lower bound). If the condition holds, it returns 1 (on time), otherwise 0 (late). In plain terms, this marks the line on time if delivered no later than the due date (and not too early beyond 2 days).

	•	is_IF – In Full flag. Formula:

is_IF = 
  IF(
    NOT(ISBLANK([Customer_IF_flag])),
      [Customer_IF_flag],
      IF( [Delivered_Qty] >= [Ordered_Qty], 1, 0 )
  )

This uses the customer’s provided in-full flag if available; otherwise, it checks if delivered quantity is greater or equal to ordered quantity. If yes, returns 1 (meaning the order line was fulfilled in full), if not, returns 0 (short delivery). In most cases this is an exact equality check (Delivered = Ordered), but using >= accounts for the rare case of an over-delivery being considered acceptable as “in full.” If we wanted to enforce exact match, we’d use == instead of >=.

	•	is_OTIF – On Time In Full flag. This is simply a combination:

is_OTIF = IF( [is_OT] = 1 && [is_IF] = 1, 1, 0 )

Or equivalently, is_OTIF = [is_OT] * [is_IF] since they are 0/1 values. This column is 1 if both on-time and in-full conditions are satisfied, otherwise 0. If a customer provided a single OTIF status field, we could alternatively use IF( NOT(ISBLANK([Customer_OTIF_flag])), [Customer_OTIF_flag], [is_OT] * [is_IF] ) to defer to their evaluation when available.

These calculated columns give a quick classification per line. We can also add other calculated columns for convenience, for example: a “Delay (Days)” column = Actual Delivery Date – Requested Date (in days) to see how late or early the line was (a negative value would mean it was that many days early, positive means days late). Another could be “Shortfall Qty” = Ordered_Qty – Delivered_Qty (showing how many units short, if any). Such columns help in detailed analysis and creating visuals (like distribution of days late, etc.).

DAX Measures for Aggregation: Using the above flags, we’ll create measures to calculate overall OTIF performance and breakdowns. Some essential measures include:
	•	Total Lines: Total Lines = COUNTROWS( FactOTIF ). This counts the number of order line records (we might restrict this to only customer lines if the fact includes some dummy unmatched records, but generally it’s all lines delivered or ordered). This is the denominator for percentage calculations.
	•	On-Time Lines: On-Time Lines = SUM( FactOTIF[is_OT] ). Since is_OT is 1 for on-time lines and 0 for others, summing it yields the count of on-time lines. Similarly, In-Full Lines = SUM(is_IF) and OTIF Lines = SUM(is_OTIF) give the counts of lines meeting those criteria. (If we preferred not to use a calculated column, we could write these as COUNTAX filters, but sum of 0/1 is simplest and efficient.)
	•	OT %: Percentage of lines on time. We can define it as:

OT % = DIVIDE( [On-Time Lines], [Total Lines] )

formatted as a percentage. This will dynamically compute the on-time delivery rate for whatever filter context is applied (overall, by customer, by month, etc.). We will create similar measures for IF % (in-full percentage) and OTIF %. For example, OTIF % = DIVIDE( [OTIF Lines], [Total Lines] ). These measures can be used in cards or chart visuals.

	•	Late Delivery Rate (or #): Although not explicitly asked, it might be useful to have the inverse metrics. For instance, “Late %” could be 1 – [OT %] (or computed as sum of lines where is_OT=0 divided by total). Similarly, “Not In Full %” = 1 – [IF %]. Or we can directly measure counts of failures: Late Lines = COUNTROWS( FILTER( FactOTIF, FactOTIF[is_OT] = 0 ) ). We might create measures for Late Lines, Short Lines, and OTIF Fail Lines. For example, OTIF Fail Lines = [Total Lines] - [OTIF Lines]. These are useful for discrepancy analysis.
	•	By Customer / Plant / Material: We do not need separate measures for each dimension – the above measures will automatically filter by the context of visuals. For instance, if we put Customer on a chart axis with OTIF % as value, Power BI will compute OTIF % per customer. Likewise for plant. However, if we want the number of late lines per customer as a measure, we might write something like:

Late Lines = CALCULATE( [Total Lines], FILTER( FactOTIF, FactOTIF[is_OT] = 0 ) )

but again, using visual filters is often enough. We can also create quick measures like “% of lines late by plant” using CALCULATE with ALLEXCEPT if needed, but typically slicing is simpler.

	•	Time Intelligence (Weekly/Monthly): To support trend analysis, we ensure our Date dimension is marked as a date table. Then we can use time intelligence if needed. For example, we might have a measure for Monthly OTIF % that is essentially the same OTIF% but evaluated each month on the axis. Simply placing OTIF % in a line chart with Month will show the trend. If we want specific time-frame calculations like Year-to-Date OTIF or Last 4 weeks, we can create measures using DAX time functions:
	•	YTD OTIF % = CALCULATE( [OTIF %], DATESYTD( DimDate[Date] ) ).
	•	Last 4 Weeks OTIF % = using DATEADD or OFFSET in the Date dimension to filter the last 28 days relative to max date.
	•	Week OTIF % could be a measure using CALCULATE([OTIF Lines], FILTER(DimDate, DimDate[IsWeekEnding]=1)) / CALCULATE([Total Lines], ...), or simpler, just use a weekly axis. We might not need special measures if the Date table has a Week number or Year-Week that we can drop in a visual.

We will also create a target measure if needed (say the business target is 95% OTIF, we can have a constant measure or a value from a target table to compare). This target can be used to show variance (like conditional formatting to highlight when OTIF% is below target).

Example Calculations:
	•	Overall OTIF %: If we had 1000 lines total and 800 met both criteria, OTIF % = 80%. This measure is dynamic.
	•	OT % by Customer: if filtered to customer = Mars, the measure calculates using only Mars’s lines (both numerator and denominator filtered to Mars context).
	•	Late % per Plant: We could create a measure Late % = 1 - [OT %] and use it with Plant filter to see which plants have higher late rates.
	•	Monthly Trend: Put DimDate[MonthYear] on X-axis and [OTIF %] as value in a line chart. The measure inherently groups by month. Optionally, we ensure the measure uses Requested Date for grouping (if we want trend by requested month). If using actual ship date, we might explicitly define OTIF % by Ship Month = CALCULATE( [OTIF %], USERELATIONSHIP(FactOTIF[Actual_Delivery_Date], DimDate[Date]) ) depending on active relationship.

These columns and measures will allow us to populate all the desired visuals: pie charts (percentages), bar charts (by plant or customer), and trends. They also allow calculations of “% of lines with OT failures, IF failures, OTIF failures” easily: e.g. OT Failure % = 1 - [OT %] (or equivalently CALCULATE([Total Lines], FactOTIF[is_OT]=0) / [Total Lines]). We can show those as separate metrics or in visuals.

Additionally, we can derive measures for the number of lines and percentage with each type of discrepancy by various breakdowns. For instance, “Late Deliveries (count) by Customer” or “Short Deliveries % by Month”. These are just variations of filtering on the flags.

In summary, we use calculated columns to mark each record’s OTIF status and DAX measures to aggregate these into meaningful KPIs (counts and percentages) at any desired level (overall, by customer, by plant, by material, by week, etc.). This combination gives the dashboard the numbers it needs for each visual, with interactive filtering handled by Power BI’s context mechanics.

5. Dashboard Visuals

The Power BI dashboard will feature intuitive visuals to help the Supply Chain Analysts quickly grasp OTIF performance and drill into problem areas. Key visuals include a summary of OTIF vs failures, breakdowns by plant and customer, trends over time, and interactive filters. Below are the proposed visuals and their roles:

Example of an OTIF dashboard overview with key metrics: OTIF %, On-Time %, In-Full %, and breakdown by supplier (analogous to customer or plant) and a trend over time.
	•	OTIF Summary (Pie/Donut and KPIs): A prominent visual on the dashboard will show the overall OTIF performance. We can use a donut chart or pie chart to illustrate the proportion of order lines that met OTIF versus those that did not. For example, a donut chart could have two segments: “OTIF Met” (in green) and “OTIF Not Met” (in red), with a label in the center showing the OTIF % (e.g. 85% OTIF). This gives an immediate sense of success vs. failure rate. Additionally, we will display the individual On-Time and In-Full percentages, since those detail where issues lie. These could be small donut charts or card visuals: e.g. a small donut showing % On-Time (perhaps 90% on time, indicating 10% late) and another for % In-Full (e.g. 92% in full). In the example image above, 55% OTIF, 61% On-Time, 88% In-Full are shown. We can mimic that: a section titled “Overview” with a big  OTIF % gauge and smaller indicators for on-time and in-full. This helps users see if low OTIF is driven more by timeliness or completeness problems. If needed, we’ll also display the total number of order lines and maybe the number of “days late” on average. For instance, a card showing “N days late” could display the average delay of late lines. Summaries of total ordered vs delivered quantities could also be shown to give context (as in the example, which lists ordered quantity vs received quantity totals).
	•	Performance by Plant (Bar Chart): To identify which internal plants are performing well or poorly, we’ll include a bar chart by plant. Each bar represents a plant’s OTIF performance. We could use a stacked bar: the green portion of the bar = % of that plant’s lines that met OTIF, and the red portion = % that failed, summing to 100%. This immediately highlights, for example, Plant A is at 95% OTIF (small red segment) whereas Plant B is only 70% OTIF (large red segment). Alternatively, we could show multiple metrics in one chart – but simplest is one bar per plant with color-coded OTIF success rate. We will sort plants from best to worst or vice versa. If the analysts also want to see breakdown by customer, we can enable a hierarchy or have slicers: for instance, a slicer for Customer could be applied so that the bar chart shows each plant’s performance for the selected customer. Conversely, we might create a bar chart by Customer to see which customer orders are hardest to serve OTIF (e.g. maybe we do well for Mars (90%) but poorly for Unilever (75%)). Both dimensions are available; we might include one primary (plants) and use the other as a filter or have a toggle. Another idea: a matrix or side-by-side bar chart to show OTIF% by plant by customer (though that can get busy). Initially, a simple horizontal bar chart listing plants with their OTIF% (and perhaps conditional formatting or a target line) will suffice.
	•	Trend Over Time (Line Chart): We will add a line chart to show OTIF performance over time (by week or month). On the X-axis we can have the timeline (e.g. Jan 2025, Feb 2025, … or Week 1, Week 2, …), and on the Y-axis the OTIF % for that period. This visual will quickly reveal if OTIF is improving, declining, or seasonal. We can plot multiple lines if desired: for example, one line for OTIF%, another for On-Time%, another for In-Full%. This way we can see if a dip in OTIF in a certain month was due to a drop in on-time or in-full performance. However, showing all three could clutter; we might just show OTIF% and perhaps use markers or tooltips for the others. We’ll include a target line on the chart (e.g. a constant 95% target) so any point below target is clearly seen. Using data labels or color highlights for points not meeting target can draw attention (as seen in the example image’s trend chart where points turn red when below target). We might implement a dynamic feature: e.g. a marker that turns red if OTIF < target for that month, green if >= target. This trend chart helps the team spot when performance issues arose (e.g. a dip in April might correlate with a known supply issue). It can be filtered by customer or plant as well (e.g. view the trend for a particular plant or customer using the slicers).
	•	Discrepancy Breakdown/Trend: In addition to overall OTIF trend, we want to visualize the reasons for failure over time. A good visual for this is a stacked column chart by month where each column is 100% of lines, split by outcome: on-time in-full (green), late (red), short (orange perhaps), both late & short if we want separate category (or we can count a line that’s late and short as just “failed” since OTIF covers both). Another approach is two line charts: one for % late and one for % short over time. For example, a line for “Late deliveries %” by month might show that in March 15% of lines were late, then improved to 5% in April, etc. Similarly for short shipments. This helps determine if timeliness or fulfillment is more problematic at different times. We could also do a pie or bar for failure reasons overall: e.g. of the lines that failed OTIF, 60% were due to being late, 30% due to short (and 10% both). However, since OTIF fail is always either or both, we might classify failures into mutually exclusive buckets: “Late Only”, “Short Only”, “Both Late & Short”. A small pie or bar could show the breakdown of OTIF failures by type of issue. As for a trend, perhaps a clustered column: for each month, one column for % late, one for % short, one for % both (or an area chart stacking late+short counts). The dashboard might incorporate one combined visual for this, or a set of measures in a tooltip or so. Since the prompt specifically mentions “discrepancy trend,” a likely interpretation is showing how the percent of lines failing OT, failing IF, failing OTIF each month changes. We could present this as three lines: Late % (which is 100 - OT% essentially), Short % (100 - IF%), and OTIF Fail % (100 - OTIF%). In practice, OTIF Fail % is not independent (it’s sort of the union of late and short). Possibly a clearer method: two area charts layered – one for late, one for short, so overlap shows both. But to keep it simple: we’ll likely show a small multiple or combined chart:
	•	For example, a line chart where the red line = Late % by month, orange line = Short % by month. The area under both can be shaded. If a line is both late and short, it contributes to both metrics, but that’s fine as they measure different aspects.
	•	This way, analysts can see in which months lateness spiked or fill rate dropped. They might see, for instance, July had a high late percentage (maybe transport issues), while September had more short shipments (maybe production issues).
	•	Drill-through Detail Table: While not a visual on the main dashboard, we will create a detail page that lists all order lines with detailed info. Users can drill-through from any high-level visual (by right-clicking a data point, e.g. a specific plant or a specific customer-month) to this detail page. The detail page will have a table visual showing columns like Customer, PO, Plant, Material, Ordered Qty, Delivered Qty, Requested Date, Delivered Date, is_OT, is_IF, is_OTIF, and perhaps Days Late or Short Qty. We will enable drill-through filters so that context (like plant = X and month = June) carries into this table, thus showing only the relevant lines (e.g. all lines for Plant X in June that were late/incomplete). Conditional formatting can be applied: for instance, highlight rows in red where is_OTIF = 0, or highlight the “Days Late” column for late deliveries. This detail allows the analyst to investigate which specific orders or materials failed and by how much, helping to find root causes (maybe a particular material or a particular large order caused most issues).
	•	Filters/Slicers: The dashboard will include slicers (filter controls) to let the user refine the view. Key slicers:
	•	Customer – a slicer (perhaps a dropdown or buttons) listing Mars, Nestlé, Unilever, Mondelez (and any future added). This lets the analyst focus on one customer’s performance at a time if desired. They could also compare by selecting multiple, but one at a time might be clearer.
	•	Plant – a slicer for plant, in case the user wants to isolate a particular plant’s performance across all visuals. (We might also allow multi-select to compare two plants, but typically one selection filters the charts).
	•	Material – a slicer (maybe a search-enabled dropdown) to look at a specific product’s OTIF performance. If an issue is suspected with a certain SKU, this filter would adjust all visuals to show metrics for that product only.
	•	PO Number – possibly a text search box where a user can enter a specific PO and jump to see its status (this might go directly to a table or we can highlight if that one PO had any late lines).
	•	Date range – although the main trend chart might show all data, a date slicer (or preset period buttons like Last 3 months, YTD, etc.) can be provided to focus the analysis on a timeframe. We could have toggle buttons for Year-to-date vs. last year, etc., or a slider slicer for months. Given the mention of weekly/monthly, a dropdown to select “Weekly” or “Monthly” aggregation might be an advanced option (using a calculated table or switching axis). But simpler is just a date range filter.

All visuals will be interconnected. For example, clicking a segment of the plant bar chart (say Plant A) can cross-filter the other visuals to show only data for Plant A. Likewise, clicking a slice of the OTIF pie (the “not OTIF” slice) could filter the bar chart to show where those failures occurred by plant or the line chart to show trend of failures – though usually we keep the pie just for high-level display. We’ll ensure the interactions make sense (some might be set to highlight vs. filter appropriately).

The dashboard layout might have an Overview section (with the pie and KPI cards), a Breakdown section (% OTIF by Plant or Customer), and a Trend section (line charts). Each visual will have clear titles, e.g. “% OTIF by Plant”, “OTIF Trend by Month (Requested Delivery Date)”, “Late vs Short Trend”, etc. We will also include a legend for any color encoding (like green = OTIF met, red = not met). If space allows, a small text box can note the definition of OTIF and the current filters context (Power BI’s built-in filter pane or a “report tooltip” can handle this as well).

By presenting the data in this way, an analyst can start at the big picture (overall OTIF%), then use the plant chart to see which plant is contributing most to failures, use the trend to see when problems are happening, and drill through to see the exact orders. For example, they might observe overall OTIF is 85%, Plant B has only 70% OTIF (problem area), mostly due to late deliveries in July (from the trend), and then drill to July’s Plant B orders to find which POs were late and coordinate with logistics on those specific cases.

6. Master Data Support

To make the dashboard user-friendly and maintainable, we will incorporate master data for plants, customers, and materials, and design the solution for ongoing refresh and expansion:
	•	Plant Master Data: Instead of showing plant codes (which might be cryptic like “423” or “PL01”), we’ll use a plant dimension table to map codes to human-readable names (e.g. “Plant 423 – Dallas Warehouse”). The plant master can also include additional info like plant location, region, or capacity if needed for future analysis. We can obtain this from the internal system or a reference Excel. The ETL will load this as DimPlant with columns [PlantCode] and [PlantName] (and any others). During refresh, if new plant codes appear in the fact (say a new distribution center comes online), we’d update the master to include it (or automatically union it if we generate the dimension from fact and have a small lookup table for names). This ensures new plants are recognized and properly labeled.
	•	Customer Master Data: Similarly, we want consistent customer labels. Since we know the four key customers (Mars, Nestlé, Unilever, Mondelez), we can create a small DimCustomer with perhaps [CustomerID] and [CustomerName], or even just use the names directly as keys if they’re unique. In our unified fact, we added a Customer column (with values like “Mars”). We can use that as the key to the customer dimension, where we could have formal names or additional info (maybe a customer code number, or grouping if needed). This dimension makes it easy to add a new customer; we’d just append their name here. If internal data also has a customer ID (like a numeric code), we could map that as well. But likely using the names directly is fine given the small number.
	•	Material Master Data: The Material dimension supports showing product descriptions. Internal data probably has material codes (SKUs) for products shipped. We can source a master list of materials from the company’s item master. DimMaterial would include [MaterialCode] (key) and fields like [MaterialName] or [Description], [Product Category], etc. Then in visuals, instead of just seeing a code like “SKU12345”, the user can see “SKU12345 – Widget A 500ml”. This is helpful if they drill down to line level or filter by product. If customers use their own product codes, we have to ensure we map to our internal code. Ideally, the data alignment uses our internal material code throughout (the matching logic assumed the Material Code is common). If not, a mapping table from each customer’s product code to our code would be needed in the ETL. But since the problem statement uses Material Code as a common key, we assume one unified code system. The material master will be updated as new products appear. We might choose to build the dimension by extracting unique material codes from the fact and merging with a lookup table of codes-to-names.
	•	Date Dimension: As mentioned, we have a date table to drive time-based analysis. We can generate this easily (covering the range of dates in the data, say the past 2-3 years and looking forward if needed). The date table includes year, quarter, month, week, etc., enabling flexible grouping (weekly OTIF vs monthly). It also allows marking working days vs weekends if needed (for on-time calculations if we only consider working days – not specified here, but something to consider in rule updates).
	•	Ongoing Refresh & Expansion: The design ensures that adding more data or new scenarios is straightforward:
	•	Data Refresh: We will connect Power BI to the data sources (maybe Excel files, CSVs, or a database). The Power Query steps (renaming, merging) will automatically apply to new records on each refresh. We’ll schedule refreshes (daily or weekly as needed). If the internal table is very large, we might implement incremental refresh (loading only new records beyond a certain date, if the data source supports it) to keep the dataset efficient.
	•	New Customers: If a new customer joins the program, we would get their order data. We can copy the existing queries for customers as a template to handle their file (adjust column mappings for that structure). Then include that in the append. Because the model uses a generic Customer dimension, the new customer will be just another member. Visuals and slicers will automatically include the new customer’s name. Any unique logic (like perhaps a different early delivery tolerance for that customer) can be handled by extending our calculated column formula (e.g. we could include a condition in is_OT that if Customer = “NewCo” use 5-day early window instead of 2, or any such rule). So rule updates per customer can be incorporated via conditional logic or parameter tables without redesigning the model.
	•	Master Data Maintenance: We should ensure the master data (plants, materials, etc.) stays up to date. If using dynamic generation (from fact) plus lookup, any new code in fact that fails to find a name could be flagged, so we know to update the lookup. We could also integrate with a database or SharePoint list for these mappings to allow easy edits by data managers.
	•	Scalability: The fact table approach will scale to handle more customers and more records. If volume grows huge, we might consider splitting fact tables or using aggregations, but given typical OTIF analysis, the data of a few large customers is manageable in Power BI with proper query folding or incremental load. We also isolate calculations in measures which are easy to adjust if the definition of OTIF changes (for example, if later the business says “on time means within +1 day instead of 0 days late”, we could just change the DAX in is_OT or even better, have a parameter for allowed lateness).
	•	Documentation & Metadata: We will document that Plant codes come from internal master, Customer names correspond to specific data sources, and Material codes are internal SKUs. This avoids confusion when interpreting the dashboard. For instance, if a customer uses a different name for a product, the team should know the mapping. (If needed, we could even include the customer’s product name in the data model as well, to show in the detail when drilling through).

In conclusion, the data model and dashboard are structured to leverage master data for clarity and to accommodate growth. Each dimension table provides context (turning codes into names), and the fact table is built to accept new rows from additional customers or time periods. The refresh process will pull in new data and apply the matching and flagging logic so that the Supply Chain team always has an up-to-date view of OTIF performance across these key customers. With this model, they can trust the data alignment (internal vs customer records matched correctly) and focus on analyzing the insights to improve delivery performance.

Sources:
	•	Inforiver, Measuring what matters: Supply chain KPIs – definitions of On-Time, In-Full, and OTIF ￼ ￼.
	•	Power BI Community, OTIF Report – on allowable delivery windows (tolerance for early/late) ￼.
	•	Power BI Community, Many-to-Many Relationships – recommendation to use a bridging table with unique keys (or merge tables) instead of direct many-to-many in data models ￼ ￼.